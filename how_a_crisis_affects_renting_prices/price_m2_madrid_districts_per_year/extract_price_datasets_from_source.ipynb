{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract rent/sell prices per m2 and number of Airbnb offers data sets\n",
    "\n",
    "In the current notebook, we are extracting the data available online into a computer readable shape (data frame). We also need to group data from different years and label it correctly according to the dates.\n",
    "\n",
    "* The source of rent and sell prices per m2 per district in Madrid is [idealista.com](https://www.idealista.com/informes-precio-vivienda) for the years 2007-2017\n",
    "* The source of Airbnb listings is [insideairbnb.com](http://insideairbnb.com/get-the-data.html) for several months in 2015, 2017 and 2018. I will need a reconstruction of the trend to extrapolate data to missing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabula import read_pdf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     8,
     18,
     46,
     55
    ]
   },
   "outputs": [],
   "source": [
    "upper = ['Barajas', 'Carabanchel',\n",
    "       'Centro', 'Chamartín', 'Chamberí', 'Ciudad Lineal', 'Fuencarral',\n",
    "       'Hortaleza', 'Latina', 'Moncloa', 'Moratalaz', 'Puente de Vallecas',\n",
    "       'Retiro', 'Salamanca', 'San Blas', 'Tetuán', 'Usera', 'Vicálvaro',\n",
    "       'Villa de Vallecas', 'Villaverde', 'Arganzuela', 'ciudadlineal',\n",
    "       'puentedevallecas', 'sanblas', 'villadevallecas', 'Madrid',\n",
    "       'CiudadLineal', 'PuentedeVallecas', 'SanBlas', 'VilladeVallecas']\n",
    "\n",
    "lower = ['barajas', 'carabanchel', 'centro', 'chamartín', 'chamberí',\n",
    "       'ciudad lineal', 'fuencarral', 'hortaleza', 'latina', 'moncloa',\n",
    "       'moratalaz', 'puente de vallecas', 'retiro', 'salamanca',\n",
    "       'san blas', 'tetuán', 'usera', 'vicálvaro', 'villa de vallecas',\n",
    "       'villaverde', 'arganzuela', 'ciudad lineal', 'puente de vallecas', \n",
    "       'san blas', 'villa de vallecas', 'madrid', 'ciudad lineal', 'puente de vallecas', \n",
    "       'san blas', 'villa de vallecas']\n",
    "\n",
    "districts_dict = dict(zip(upper, lower))\n",
    "\n",
    "def clean_tabula_read_pdf_parsed_data(data_frame, year, columns, district=0):\n",
    "    # extract the total of madrid data\n",
    "    all_madrid = data_frame.tail(1)\n",
    "    if len([x for x in all_madrid.iloc[0,district].split() if x in ['Madrid','madrid']]) > 0:\n",
    "        data_frame.drop(data_frame.index[len(data_frame)-1], inplace=True)\n",
    "    \n",
    "    # include header as a new row\n",
    "    a = pd.DataFrame(data_frame.columns.tolist()).T\n",
    "    a.columns = data_frame.columns.tolist()\n",
    "    data_frame_ = pd.concat([data_frame, a], axis=0)\n",
    "    \n",
    "    # clean district names\n",
    "    if district == 0:\n",
    "        districts = data_frame_[data_frame.columns.tolist()[district]].str.split().apply(lambda x: ' '.join(x[1:]))\n",
    "        data_frame_[data_frame.columns.tolist()[district]] = districts\n",
    "    else:\n",
    "        districts = data_frame_.iloc[:,district].tolist()\n",
    "        data_frame_[data_frame.columns.tolist()[district]] = districts\n",
    "    \n",
    "    # add all madrid data, rename columns and add year label\n",
    "    if len([x for x in all_madrid.iloc[0,district].split() if x in ['Madrid','madrid']]) > 0:\n",
    "        c = pd.concat([data_frame_, all_madrid], axis=0)\n",
    "    else:\n",
    "        c = data_frame_.copy()\n",
    "    c.columns = columns\n",
    "    c['year'] = year\n",
    "    return c.loc[:,['district','price_m2','year']]\n",
    "\n",
    "def clean_rent_prices_2012(data):\n",
    "    a = data.loc[3:]\n",
    "    a.loc[:,'price_m2'] = a.loc[:,0].str.split().apply(lambda x: x[-1:][0])\n",
    "    a.loc[:,'jun_prev_year'] = a.loc[:,0].str.split().apply(lambda x: x[-2:-1][0])\n",
    "    a.loc[:,'district'] = a.loc[:,0].str.split().apply(lambda x: ' '.join(x[1:-2]))\n",
    "    a.loc[:,'jun_year'] = a[1]\n",
    "    a.loc[:,'year'] = 2012\n",
    "    return a.loc[:,['district','price_m2','year']]\n",
    "\n",
    "def clean_sale_prices_special(data):\n",
    "    data_ = data.copy()\n",
    "    col_name = data_.columns[2].split()[1]\n",
    "    data_[col_name] = data_.iloc[:,2].str.split().apply(lambda x: x[1])\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Build AirBnB dataset 2010-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load and join AirBnB listings and reviews\n",
    "airbnb_source = \"http://insideairbnb.com/get-the-data.html\"\n",
    "abnb_listings = pd.read_csv(\"./data/airbnb_listints.csv\")\n",
    "abnb_reviews = pd.read_csv(\"./data/airbnb_reviews.csv\").rename(columns={'date':'date_review'})\n",
    "\n",
    "# Assign reviews to each listing\n",
    "abnb = abnb_listings.merge(abnb_reviews, left_on='id', right_on='listing_id')\n",
    "\n",
    "abnb.to_csv('./data/airbnb_complete.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load mortage executions historical data for madrid (CGPJ) 2007-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load CGPJ evictions data\n",
    "cgpj_source = \"http://www.poderjudicial.es/cgpj/es/Temas/Estadistica-Judicial/Estudios-e-Informes/Efecto-de-la-Crisis-en-los-organos-judiciales/\"\n",
    "mort_executions = pd.read_csv(\"./data/madrid_ejec_hipotec_cgpj.csv\")\n",
    "\n",
    "# Clean and transpose source data\n",
    "mort_executions = mort_executions.ix[:,['Total 2007', 'Total 2008', 'Total 2009', 'Total 2010', 'Total 2011',\n",
    "                   'Total 2012', 'Total 2013', 'Total 2014', 'Total 2015', 'Total 2016',\n",
    "                   'Total 2017']].T.reset_index().rename(columns={0:'mortage_executions','index':'year'})\n",
    "mort_executions['year'] = mort_executions['year'].apply(lambda x: x.split(' ',1)[1])\n",
    "\n",
    "mort_executions.to_csv(\"./data/c_madrid_ejec_hipotec_cgpj.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load data of price/m2 for selling 2007-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load readable\n",
    "sale_2014 = read_pdf('./data/anio-2014.pdf')\n",
    "sale_2015 = read_pdf('./data/anio-2015.pdf')\n",
    "sale_2016 = read_pdf('./data/anio-2016.pdf')\n",
    "sale_2017 = read_pdf('./data/anio-2017.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse readable data\n",
    "cols_2 = ['district','maximum','jun_prev_year','trash','jun_year','max_var','anual_var','quarterly_var','price_m2']\n",
    "cols_3 = ['trash','district','maximum','jun_prev_year','price_m2','jun_year','max_var','anual_var','quarterly_var']\n",
    "\n",
    "sale_2014_ = clean_sale_prices_special(sale_2014)\n",
    "sale_2016_ = clean_sale_prices_special(sale_2016)\n",
    "sale_2015.iloc[:,1] = sale_2015.iloc[:,1].str.replace(' ', '')\n",
    "sale_2017.iloc[:,1] = sale_2017.iloc[:,1].str.replace(' ', '')\n",
    "\n",
    "sale_2014_ = clean_tabula_read_pdf_parsed_data(sale_2014_, 2014, cols_2)\n",
    "sale_2015_ = clean_tabula_read_pdf_parsed_data(sale_2015, 2015, cols_3, district=1)\n",
    "sale_2016_ = clean_tabula_read_pdf_parsed_data(sale_2016_, 2016, cols_2)\n",
    "sale_2017_ = clean_tabula_read_pdf_parsed_data(sale_2017, 2017, cols_3, district=1)\n",
    "\n",
    "sale_readable = pd.concat([sale_2014_, sale_2015_, sale_2016_, sale_2017_], axis=0)\n",
    "sale_readable[\"district\"].replace(districts_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load non readable manually parsed\n",
    "sale_non_readable = pd.read_csv('./data/sale_manually_parsed.csv')\n",
    "\n",
    "# concatenate all sale data\n",
    "sale_dataset = pd.concat([sale_readable, sale_non_readable], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_dataset.to_csv('./data/sale_price_m2_districts.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load data of price/m2 for renting 2007-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load readable\n",
    "rent_2009 = read_pdf('./data/alquiler-2009.pdf')\n",
    "rent_2010 = read_pdf('./data/alquiler-2010.pdf')\n",
    "rent_2011 = read_pdf('./data/alquiler-2011.pdf')\n",
    "rent_2012 = read_pdf('./data/alquiler-2012.pdf', multiple_tables=True)[0]\n",
    "rent_2014 = read_pdf('./data/alquiler-2014.pdf')\n",
    "rent_2015 = read_pdf('./data/alquiler-2015.pdf')\n",
    "rent_2016 = read_pdf('./data/alquiler-2016.pdf')\n",
    "rent_2017 = read_pdf('./data/alquiler-2017.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse and clean readable data\n",
    "cols_2 = ['district','jan_year','price_m2','ene_next_year','trash']\n",
    "cols_12 = ['district','jun_prev_year','price_m2','jun_year']\n",
    "cols_1 = ['district','jun_prev_year','price_m2','jun_year','max_var','anual_var','quarterly_var']\n",
    "cols_3 = ['district','maximum','jun_prev_year','price_m2','jun_year','max_var','anual_var','quarterly_var']\n",
    "\n",
    "rent_2009_ = clean_tabula_read_pdf_parsed_data(rent_2009, 2009, cols_1)\n",
    "rent_2010_ = clean_tabula_read_pdf_parsed_data(rent_2010, 2010, cols_2)\n",
    "rent_2011_ = clean_tabula_read_pdf_parsed_data(rent_2011, 2011, cols_2)\n",
    "rent_2012_ = clean_rent_prices_2012(rent_2012)\n",
    "rent_2014_ = clean_tabula_read_pdf_parsed_data(rent_2014, 2014, cols_3)\n",
    "rent_2015_ = clean_tabula_read_pdf_parsed_data(rent_2015, 2015, cols_3)\n",
    "rent_2016_ = clean_tabula_read_pdf_parsed_data(rent_2016, 2016, cols_3)\n",
    "rent_2017_ = clean_tabula_read_pdf_parsed_data(rent_2017, 2017, cols_3)\n",
    "\n",
    "rent_readable_dataset = pd.concat([rent_2009_,rent_2010_,rent_2011_,rent_2012_,rent_2014_,\n",
    "                                   rent_2015_,rent_2016_,rent_2017_], axis=0).reset_index(drop=True)\n",
    "rent_readable_dataset[\"district\"].replace(districts_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load non readable manually parsed\n",
    "rent_non_readable = pd.read_csv('./data/rent_manually_parsed.csv')\n",
    "\n",
    "# concatenate with previous dataset\n",
    "rent_dataset = pd.concat([rent_readable_dataset, rent_non_readable], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_dataset.to_csv('./data/rent_price_m2_districts.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
